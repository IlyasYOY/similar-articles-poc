{% extends "base.html" %}

{% block title %} Recommender {% endblock %}
{% block content %}
    <div class="w3-panel">
        <ul class="w3-ul w3-border w3-card-4">
            <li><h2>Available algorithms</h2></li>
            <li>
                <div class="w3-dropdown-hover w3-light-grey">
                    Bag-of-Words
                    <div class="w3-dropdown-content w3-card-4" style="width: 50em">
                        <img src="/static/img/bow.png" alt="Bag-of-Words" style="width:100%"/>
                        <p>Bag-Of-Words</p>
                        <p>The bag-of-words model is a simplifying representation used in natural language
                            processing and information retrieval (IR). In this model, a text (such as a sentence or
                            a document) is represented as the bag (multiset) of its words, disregarding grammar and
                            even word order but keeping multiplicity</p>
                    </div>
                </div>
            </li>
            <li>
                <div class="w3-dropdown-hover w3-light-grey">
                    Term Frequency–Inverse Document Frequency
                    <div class="w3-dropdown-content w3-card-4" style="width: 50em">
                        <img src="/static/img/tfidf.png" alt="TF-IDF" style="width:100%"/>
                        <p>TF-IDF</p>
                        <p>In information retrieval, tf–idf or TF-IDF, short for term frequency–inverse document
                            frequency, is a numerical statistic that is intended to reflect how important a word is
                            to a document in a collection or corpus.[1] It is often used as a weighting factor in
                            searches of information retrieval, text mining, and user modeling. The tf–idf value
                            increases proportionally to the number of times a word appears in the document and is
                            offset by the number of documents in the corpus that contain the word, which helps to
                            adjust for the fact that some words appear more frequently in general. Tf–idf is one of
                            the most popular term-weighting schemes today; 83% of text-based recommender systems in
                            digital libraries use tf–idf.</p>
                    </div>
                </div>
            </li>
            <li>
                <div class="w3-dropdown-hover w3-light-grey">
                    Doc2Vec
                    <div class="w3-dropdown-content w3-card-4" style="width: 50em">
                        <img src="/static/img/doc2vec.png" alt="TF-IDF" style="width:100%"/>
                        <p>Doc2Vec</p>
                        <p>Doc2vec is an unsupervised algorithm to generate vectors for sentence/paragraphs/documents.
                            The algorithm is an adaptation of word2vec which can generate vectors for words.</p>
                    </div>
                </div>
            </li>
        </ul>
    </div>
    <div class="w3-panel">
        <ul class="w3-ul w3-border w3-card-4">
            {% for article in articles %}
                <li>
                    <div class="w3-bar w3-border w3-light-grey w3-round-xlarge">
                        <div class="w3-bar-item">
                            <p>
                                ID: {{ article.id }}
                            </p>
                            <p>
                                Title: "{{ article.title }}"
                            </p>
                            {% if article.abstract %}
                                <p>
                                    Abstract: "{{ article.abstract }}"
                                </p>
                            {% endif %}
                        </div>
                        <a href="/recommend/{{ article.id }}?algorithm=bow"
                           class="w3-bar-item w3-button w3-right">BoW</a>
                        <a href="/recommend/{{ article.id }}?algorithm=tfidf"
                           class="w3-bar-item w3-button w3-right">TF-IDF</a>
                        <a href="/recommend/{{ article.id }}?algorithm=doc2vec"
                           class="w3-bar-item w3-button w3-right">Doc2Vec</a>
                    </div>
                </li>
            {% endfor %}
        </ul>
    </div>
    <div class="w3-bar w3-border w3-round">
        <a href="/?from={{ from_index if from_index < 11 else from_index - 10 }}" class="w3-button">&#10094;
            Previous</a>
        <a href="/?from={{ from_index + 10 }}" class="w3-button w3-right">Next &#10095;</a>
    </div>
{% endblock %}